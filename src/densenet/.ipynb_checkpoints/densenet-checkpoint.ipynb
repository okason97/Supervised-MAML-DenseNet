{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from densenet import densenet_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From <ipython-input-2-0dcb167e88d7>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# data\n",
    "rotation_range = 20\n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2\n",
    "horizontal_flip = True\n",
    "vertical_flip = True\n",
    "shear_range = 0\n",
    "zoom_range = 0.5\n",
    "size = (32,32)\n",
    "\n",
    "# model\n",
    "nb_filter = 64\n",
    "growth_rate = 16\n",
    "nb_layers = [6, 12, 24, 16]\n",
    "reduction = 0.5\n",
    "\n",
    "# training\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "max_patience = 20\n",
    "batch_size = 128\n",
    "\n",
    "# log\n",
    "log_freq = 1\n",
    "models_directory = 'results/models/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"{}-growth-{}-densenet\".format(\n",
    "    '-'.join([str(i) for i in nb_layers]),\n",
    "    growth_rate) + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "ds_train = tfds.load('cifar100', split='train', shuffle_files=True, batch_size=-1)\n",
    "train_np_ds = tfds.as_numpy(ds_train)\n",
    "ds_test = tfds.load('cifar100', split='test', shuffle_files=False, batch_size=-1)\n",
    "test_np_ds = tfds.as_numpy(ds_test)\n",
    "\n",
    "x_train, y_train = train_np_ds[\"image\"], train_np_ds[\"label\"]\n",
    "x_test, y_test = test_np_ds[\"image\"], test_np_ds[\"label\"]\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]\n",
    "\n",
    "info = tfds.builder('cifar100').info\n",
    "n_classes = info.features['label'].num_classes\n",
    "img_shape = info.features['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=rotation_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip = vertical_flip,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "test_datagen.fit(x_train)\n",
    "\n",
    "# create data generators\n",
    "train_gen =  datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_gen = test_datagen.flow(x_test, y_test , batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_gen:\n",
    "    print(images[0])\n",
    "    plt.imshow(images[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet_model(classes=n_classes, nb_filter=nb_filter, shape=img_shape, growth_rate=growth_rate, nb_layers=nb_layers, reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.cast(images, tf.float32), training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(tf.cast(images, tf.float32), training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary writers\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/train/' + identifier)\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "\n",
    "min_loss = 100\n",
    "min_loss_acc = 0\n",
    "patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "Epoch: 0, Train Loss: 4.086111068725586, Train Acc:7.664000034332275, Test Loss: 4.151409149169922, Test Acc: 6.109999656677246, Time: 48.307044982910156 s\n",
      "Epoch: 1, Train Loss: 3.6957974433898926, Train Acc:12.707999229431152, Test Loss: 4.030071258544922, Test Acc: 9.470000267028809, Time: 24.880091905593872 s\n",
      "Epoch: 2, Train Loss: 3.480161428451538, Train Acc:16.373998641967773, Test Loss: 4.110396385192871, Test Acc: 10.329999923706055, Time: 24.72502589225769 s\n",
      "Epoch: 3, Train Loss: 3.332418441772461, Train Acc:18.98200035095215, Test Loss: 3.6584692001342773, Test Acc: 14.180000305175781, Time: 24.63539481163025 s\n",
      "Epoch: 4, Train Loss: 3.2180123329162598, Train Acc:21.038000106811523, Test Loss: 3.8159565925598145, Test Acc: 14.120000839233398, Time: 24.652124166488647 s\n",
      "Epoch: 5, Train Loss: 3.118060350418091, Train Acc:22.81599998474121, Test Loss: 3.6449387073516846, Test Acc: 15.140000343322754, Time: 24.84588861465454 s\n",
      "Epoch: 6, Train Loss: 3.0322353839874268, Train Acc:24.381999969482422, Test Loss: 3.591418981552124, Test Acc: 16.25, Time: 24.8433735370636 s\n",
      "Epoch: 7, Train Loss: 2.9535863399505615, Train Acc:25.90999984741211, Test Loss: 3.515903949737549, Test Acc: 17.90999984741211, Time: 24.88148260116577 s\n",
      "Epoch: 8, Train Loss: 2.8730571269989014, Train Acc:27.371999740600586, Test Loss: 3.6027348041534424, Test Acc: 16.479999542236328, Time: 24.812320947647095 s\n",
      "Epoch: 9, Train Loss: 2.8103322982788086, Train Acc:28.743999481201172, Test Loss: 3.5459587574005127, Test Acc: 18.440000534057617, Time: 24.836929321289062 s\n",
      "Epoch: 10, Train Loss: 2.751495361328125, Train Acc:29.73200035095215, Test Loss: 3.2803966999053955, Test Acc: 21.770000457763672, Time: 24.787521839141846 s\n",
      "Epoch: 11, Train Loss: 2.689042329788208, Train Acc:31.009998321533203, Test Loss: 3.2469823360443115, Test Acc: 22.610000610351562, Time: 25.18902587890625 s\n",
      "Epoch: 12, Train Loss: 2.6389453411102295, Train Acc:31.968000411987305, Test Loss: 3.1870005130767822, Test Acc: 23.790000915527344, Time: 24.991870403289795 s\n",
      "Epoch: 13, Train Loss: 2.5905239582061768, Train Acc:32.802001953125, Test Loss: 3.2084994316101074, Test Acc: 23.80000114440918, Time: 24.758301496505737 s\n",
      "Epoch: 14, Train Loss: 2.5343339443206787, Train Acc:33.95800018310547, Test Loss: 3.199244976043701, Test Acc: 23.559999465942383, Time: 24.743125200271606 s\n",
      "Epoch: 15, Train Loss: 2.4916727542877197, Train Acc:34.96200180053711, Test Loss: 3.4529411792755127, Test Acc: 21.35999870300293, Time: 25.085424423217773 s\n",
      "Epoch: 16, Train Loss: 2.451803684234619, Train Acc:35.82200241088867, Test Loss: 3.2869884967803955, Test Acc: 23.56999969482422, Time: 25.408888816833496 s\n",
      "Epoch: 17, Train Loss: 2.408604621887207, Train Acc:36.53999710083008, Test Loss: 3.220170021057129, Test Acc: 24.190000534057617, Time: 24.822948694229126 s\n",
      "Epoch: 18, Train Loss: 2.3624117374420166, Train Acc:37.66600036621094, Test Loss: 3.211580753326416, Test Acc: 24.75, Time: 24.66290307044983 s\n",
      "Epoch: 19, Train Loss: 2.332042694091797, Train Acc:38.5359992980957, Test Loss: 3.246342420578003, Test Acc: 24.600000381469727, Time: 25.491711378097534 s\n",
      "Epoch: 20, Train Loss: 2.2937567234039307, Train Acc:39.10799789428711, Test Loss: 3.2141494750976562, Test Acc: 24.200000762939453, Time: 26.48651647567749 s\n",
      "Epoch: 21, Train Loss: 2.2519869804382324, Train Acc:39.996002197265625, Test Loss: 3.269343137741089, Test Acc: 24.779998779296875, Time: 27.390523195266724 s\n",
      "Epoch: 22, Train Loss: 2.221637487411499, Train Acc:40.715999603271484, Test Loss: 3.3254480361938477, Test Acc: 24.439998626708984, Time: 25.185312032699585 s\n",
      "Epoch: 23, Train Loss: 2.190464735031128, Train Acc:41.236000061035156, Test Loss: 3.2898106575012207, Test Acc: 25.790000915527344, Time: 24.492541074752808 s\n",
      "Epoch: 24, Train Loss: 2.1583428382873535, Train Acc:41.81800079345703, Test Loss: 3.202705144882202, Test Acc: 26.19999885559082, Time: 24.719427585601807 s\n",
      "Epoch: 25, Train Loss: 2.127032518386841, Train Acc:42.582000732421875, Test Loss: 3.119889259338379, Test Acc: 27.1200008392334, Time: 24.599529027938843 s\n",
      "Epoch: 26, Train Loss: 2.0932188034057617, Train Acc:43.32400131225586, Test Loss: 3.0196104049682617, Test Acc: 28.380001068115234, Time: 24.545137643814087 s\n",
      "Epoch: 27, Train Loss: 2.065295457839966, Train Acc:43.900001525878906, Test Loss: 3.165355682373047, Test Acc: 28.270000457763672, Time: 24.55098009109497 s\n",
      "Epoch: 28, Train Loss: 2.025813579559326, Train Acc:44.865997314453125, Test Loss: 3.2669434547424316, Test Acc: 25.989999771118164, Time: 24.460038423538208 s\n",
      "Epoch: 29, Train Loss: 2.000284194946289, Train Acc:45.79800033569336, Test Loss: 3.139129638671875, Test Acc: 27.700000762939453, Time: 24.60972785949707 s\n",
      "Epoch: 30, Train Loss: 1.9709528684616089, Train Acc:46.22800064086914, Test Loss: 3.1014175415039062, Test Acc: 28.75, Time: 24.6176278591156 s\n",
      "Epoch: 31, Train Loss: 1.9432340860366821, Train Acc:46.49800109863281, Test Loss: 3.2611656188964844, Test Acc: 26.920000076293945, Time: 24.657800912857056 s\n",
      "Epoch: 32, Train Loss: 1.90884268283844, Train Acc:47.63999938964844, Test Loss: 3.2165908813476562, Test Acc: 26.94999885559082, Time: 24.44980263710022 s\n",
      "Epoch: 33, Train Loss: 1.886441707611084, Train Acc:48.12200164794922, Test Loss: 3.297513484954834, Test Acc: 25.799999237060547, Time: 24.47531247138977 s\n",
      "Epoch: 34, Train Loss: 1.8651220798492432, Train Acc:48.57400131225586, Test Loss: 3.317211627960205, Test Acc: 26.660001754760742, Time: 24.62518310546875 s\n",
      "Epoch: 35, Train Loss: 1.8401325941085815, Train Acc:49.262001037597656, Test Loss: 3.3248515129089355, Test Acc: 26.420000076293945, Time: 24.549286127090454 s\n",
      "Epoch: 36, Train Loss: 1.8109831809997559, Train Acc:49.61000061035156, Test Loss: 3.0891268253326416, Test Acc: 28.880001068115234, Time: 25.38170576095581 s\n",
      "Epoch: 37, Train Loss: 1.7834738492965698, Train Acc:50.400001525878906, Test Loss: 3.252713441848755, Test Acc: 27.25, Time: 24.467834949493408 s\n",
      "Epoch: 38, Train Loss: 1.763424277305603, Train Acc:50.87000274658203, Test Loss: 3.226513624191284, Test Acc: 28.130001068115234, Time: 24.447359323501587 s\n",
      "Epoch: 39, Train Loss: 1.738674521446228, Train Acc:51.455997467041016, Test Loss: 3.245164394378662, Test Acc: 28.150001525878906, Time: 24.482710599899292 s\n",
      "Epoch: 40, Train Loss: 1.7243911027908325, Train Acc:51.92599868774414, Test Loss: 3.233490228652954, Test Acc: 27.979999542236328, Time: 24.48012065887451 s\n",
      "Epoch: 41, Train Loss: 1.6964057683944702, Train Acc:52.297996520996094, Test Loss: 3.2525434494018555, Test Acc: 28.93000030517578, Time: 24.55210518836975 s\n",
      "Epoch: 42, Train Loss: 1.6895883083343506, Train Acc:52.84600067138672, Test Loss: 3.2999703884124756, Test Acc: 26.510000228881836, Time: 24.722163200378418 s\n",
      "Epoch: 43, Train Loss: 1.649246096611023, Train Acc:53.534000396728516, Test Loss: 3.4130823612213135, Test Acc: 27.1200008392334, Time: 24.670795440673828 s\n",
      "Epoch: 44, Train Loss: 1.6300426721572876, Train Acc:54.20800018310547, Test Loss: 3.3675196170806885, Test Acc: 27.1200008392334, Time: 24.60035729408264 s\n",
      "Epoch: 45, Train Loss: 1.6134159564971924, Train Acc:54.487998962402344, Test Loss: 3.4099724292755127, Test Acc: 27.260000228881836, Time: 25.563469886779785 s\n"
     ]
    }
   ],
   "source": [
    "print(\"starting training\")\n",
    "time_record = ''\n",
    "for epoch in range(epochs):\n",
    "    time_start = time.time()\n",
    "    batches = 0\n",
    "    for images, labels in train_gen:\n",
    "        train_step(images, labels)\n",
    "        batches += 1\n",
    "        if batches >= train_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    batches = 0\n",
    "    all_predictions = np.array([]).reshape(0, n_classes)\n",
    "    all_labels = np.array([]).reshape(0, n_classes)\n",
    "    for test_images, test_labels in test_gen:\n",
    "        all_predictions = np.vstack((all_predictions, test_step(test_images, test_labels)))\n",
    "        all_labels = np.vstack((all_labels, tf.one_hot(test_labels, n_classes)))\n",
    "        batches += 1\n",
    "        if batches >= test_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    time_finish = time.time()\n",
    "    end_time = (time_finish-time_start)\n",
    "    time_record = time_record + '{:.3f} s \\n'.format(end_time)\n",
    "\n",
    "    if (epoch % log_freq == 0):\n",
    "        print ('Epoch: {}, Train Loss: {}, Train Acc:{}, Test Loss: {}, Test Acc: {}, Time: {} s'.format(\n",
    "               epoch,\n",
    "               train_loss.result(),\n",
    "               train_accuracy.result()*100,\n",
    "               test_loss.result(),\n",
    "               test_accuracy.result()*100,\n",
    "               end_time))\n",
    "\n",
    "        if (test_loss.result() < min_loss):    \n",
    "            if not os.path.exists(models_directory):\n",
    "                os.makedirs(models_directory)\n",
    "            # serialize weights to HDF5\n",
    "            model.save_weights(models_directory + \"best{}.h5\".format(identifier))\n",
    "            min_loss = test_loss.result()\n",
    "            min_loss_acc = test_accuracy.result()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "            #tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "            train_loss.reset_states()           \n",
    "            train_accuracy.reset_states()           \n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            test_loss.reset_states()           \n",
    "            test_accuracy.reset_states()   \n",
    "            # save confusion matrix\n",
    "            con_mat = tf.math.confusion_matrix(\n",
    "                labels=np.argmax(all_labels, axis=1), \n",
    "                predictions=np.argmax(all_predictions, axis=1),\n",
    "                num_classes=n_classes).numpy()\n",
    "            con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "            con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                                 index = classes, \n",
    "                                 columns = classes)\n",
    "            figure = plt.figure(figsize=(8, 8))\n",
    "            sns.heatmap(con_mat_df, annot=False,cmap=plt.cm.Blues)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(figure)\n",
    "            buf.seek(0)\n",
    "            image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "\n",
    "    if patience >= max_patience:\n",
    "        break\n",
    "\n",
    "with open(os.path.join('results/', identifier), \"w\") as file1:\n",
    "    file1.write(time_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
