{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from densenet import densenet_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From <ipython-input-2-0dcb167e88d7>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# data\n",
    "rotation_range = 20\n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2\n",
    "horizontal_flip = True\n",
    "vertical_flip = True\n",
    "shear_range = 0\n",
    "zoom_range = 0.5\n",
    "size = (32,32)\n",
    "\n",
    "# model\n",
    "nb_filter = 64\n",
    "growth_rate = 16\n",
    "nb_layers = [6, 12, 24, 16]\n",
    "reduction = 0.5\n",
    "\n",
    "# training\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "max_patience = 100\n",
    "batch_size = 64\n",
    "\n",
    "# log\n",
    "log_freq = 1\n",
    "models_directory = 'results/models/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"{}-growth-{}-densenet\".format(\n",
    "    '-'.join([str(i) for i in nb_layers]),\n",
    "    growth_rate) + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "ds_train = tfds.load('cifar100', split='train', shuffle_files=True, batch_size=-1)\n",
    "train_np_ds = tfds.as_numpy(ds_train)\n",
    "ds_test = tfds.load('cifar100', split='test', shuffle_files=False, batch_size=-1)\n",
    "test_np_ds = tfds.as_numpy(ds_test)\n",
    "\n",
    "x_train, y_train = train_np_ds[\"image\"], train_np_ds[\"label\"]\n",
    "x_test, y_test = test_np_ds[\"image\"], test_np_ds[\"label\"]\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "train_size = 100\n",
    "meta_train_size = 30\n",
    "test_size = x_test.shape[0]\n",
    "\n",
    "info = tfds.builder('cifar100').info\n",
    "n_classes = info.features['label'].num_classes\n",
    "img_shape = info.features['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=rotation_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip = vertical_flip,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "test_datagen.fit(x_test)\n",
    "\n",
    "# create data generators\n",
    "train_gen =  datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_gen = test_datagen.flow(x_test, y_test , batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  ...\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]]\n",
      "\n",
      " [[-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  ...\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]]\n",
      "\n",
      " [[-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  ...\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]\n",
      "  [-1.3062079  -1.3746256  -1.2926631 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.1057317   1.7984155   1.3102554 ]\n",
      "  [ 2.1269028   1.8619365   1.378013  ]\n",
      "  [ 2.152497    1.9285144   1.4425266 ]\n",
      "  ...\n",
      "  [ 1.979338    1.3523607   0.9136766 ]\n",
      "  [ 1.9965872   1.2650146   0.80188876]\n",
      "  [ 1.8517622   1.2034781   0.8237341 ]]\n",
      "\n",
      " [[ 2.0994208   1.8274018   1.3009883 ]\n",
      "  [ 2.1049902   1.8745041   1.3631009 ]\n",
      "  [ 2.1214595   1.9265145   1.4286456 ]\n",
      "  ...\n",
      "  [ 1.5321825   1.0509412   0.79759496]\n",
      "  [ 1.6661681   1.0889362   0.77087504]\n",
      "  [ 1.5629036   1.0559423   0.79929805]]\n",
      "\n",
      " [[ 2.0757926   1.8329341   1.2810017 ]\n",
      "  [ 2.0963523   1.89766     1.3649045 ]\n",
      "  [ 2.1232474   1.9536737   1.4472888 ]\n",
      "  ...\n",
      "  [ 1.1646961   0.96053314  0.94340485]\n",
      "  [ 1.345858    1.036852    0.9082559 ]\n",
      "  [ 1.3986952   1.058452    0.88956696]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_gen:\n",
    "    print(images[0])\n",
    "    plt.imshow(images[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet_model(classes=n_classes, nb_filter=nb_filter, shape=img_shape, growth_rate=growth_rate, nb_layers=nb_layers, reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "meta_optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.cast(images, tf.float32), training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def meta_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.cast(images, tf.float32), training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    return gradients\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(tf.cast(images, tf.float32), training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary writers\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/train/' + identifier)\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "\n",
    "min_loss = 100\n",
    "min_loss_acc = 0\n",
    "patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "Epoch: 0, Train Loss: 4.568687915802002, Train Acc:2.703125, Test Loss: 4.609249114990234, Test Acc: 1.0, Time: 34.55236196517944 s\n",
      "Epoch: 1, Train Loss: 4.5362138748168945, Train Acc:3.515625, Test Loss: 4.609953880310059, Test Acc: 1.0199999809265137, Time: 8.50827431678772 s\n",
      "Epoch: 2, Train Loss: 4.513925552368164, Train Acc:3.281249761581421, Test Loss: 4.610660552978516, Test Acc: 1.0, Time: 8.648367166519165 s\n",
      "Epoch: 3, Train Loss: 4.524226188659668, Train Acc:3.59375, Test Loss: 4.6080732345581055, Test Acc: 1.0, Time: 8.644186735153198 s\n",
      "Epoch: 4, Train Loss: 4.51953125, Train Acc:3.078125, Test Loss: 4.6109137535095215, Test Acc: 1.2000000476837158, Time: 8.714020729064941 s\n",
      "Epoch: 5, Train Loss: 4.476430416107178, Train Acc:3.875, Test Loss: 4.613243579864502, Test Acc: 1.0700000524520874, Time: 8.655107259750366 s\n",
      "Epoch: 6, Train Loss: 4.510122776031494, Train Acc:3.447733163833618, Test Loss: 4.615306377410889, Test Acc: 1.0, Time: 16.10551929473877 s\n",
      "Epoch: 7, Train Loss: 4.465352535247803, Train Acc:3.5, Test Loss: 4.610968589782715, Test Acc: 1.090000033378601, Time: 8.362735271453857 s\n",
      "Epoch: 8, Train Loss: 4.452762603759766, Train Acc:4.0, Test Loss: 4.612850666046143, Test Acc: 1.0, Time: 8.312675476074219 s\n",
      "Epoch: 9, Train Loss: 4.458216667175293, Train Acc:3.671874761581421, Test Loss: 4.613669395446777, Test Acc: 1.0, Time: 8.357641220092773 s\n",
      "Epoch: 10, Train Loss: 4.469268798828125, Train Acc:3.796875, Test Loss: 4.609368324279785, Test Acc: 1.1399999856948853, Time: 8.482539892196655 s\n",
      "Epoch: 11, Train Loss: 4.442453861236572, Train Acc:4.046875, Test Loss: 4.609695911407471, Test Acc: 1.0, Time: 8.328424215316772 s\n",
      "Epoch: 12, Train Loss: 4.457370758056641, Train Acc:4.061712741851807, Test Loss: 4.611962795257568, Test Acc: 1.0, Time: 8.373613357543945 s\n",
      "Epoch: 13, Train Loss: 4.460562229156494, Train Acc:4.078125, Test Loss: 4.613015174865723, Test Acc: 1.0, Time: 8.430985927581787 s\n",
      "Epoch: 14, Train Loss: 4.437164306640625, Train Acc:4.140625, Test Loss: 4.611978054046631, Test Acc: 1.0, Time: 8.309860706329346 s\n",
      "Epoch: 15, Train Loss: 4.391458988189697, Train Acc:4.578125, Test Loss: 4.611199855804443, Test Acc: 1.0, Time: 8.277459621429443 s\n",
      "Epoch: 16, Train Loss: 4.425344467163086, Train Acc:4.53125, Test Loss: 4.613076210021973, Test Acc: 1.0, Time: 8.30339527130127 s\n",
      "Epoch: 17, Train Loss: 4.409480571746826, Train Acc:4.34375, Test Loss: 4.612034320831299, Test Acc: 1.0, Time: 8.462484121322632 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d8328d028d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"starting training\")\n",
    "time_record = ''\n",
    "for epoch in range(epochs):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # get the weights of the initial model that will do the meta learning\n",
    "    meta_model_weights = model.get_weights()\n",
    "\n",
    "    # train on the task (one epoch)\n",
    "    batches = 0\n",
    "    for images, labels in train_gen:\n",
    "        train_step(images, labels)\n",
    "        batches += 1\n",
    "        if batches >= train_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    # test the newly trained model on the training set\n",
    "    batches = 0\n",
    "    all_predictions = np.array([]).reshape(0, n_classes)\n",
    "    all_labels = np.array([]).reshape(0, n_classes)\n",
    "    for test_images, test_labels in test_gen:\n",
    "        test_predictions = test_step(test_images, test_labels)\n",
    "        all_predictions = np.vstack((all_predictions, test_predictions))\n",
    "        all_labels = np.vstack((all_labels, tf.one_hot(test_labels, n_classes)))\n",
    "        batches += 1\n",
    "        if batches >= test_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break            \n",
    "\n",
    "    # test on the validation set the improvement achieved on one epoch for the meta learning\n",
    "    batches = 0\n",
    "    sum_gradients = np.zeros_like(model.trainable_variables)\n",
    "    for images, labels in train_gen:\n",
    "        gradients = meta_step(images, labels)\n",
    "        gradients = np.array([np.array(x) for x in gradients])\n",
    "        sum_gradients = sum_gradients + gradients\n",
    "        batches += 1\n",
    "        if batches >= meta_train_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    # set weights of the model to the weights of the original model\n",
    "    model.set_weights(meta_model_weights)                        \n",
    "\n",
    "    # update the weights of the meta learning model using the loss obtained from testing\n",
    "    meta_optimizer.apply_gradients(zip(sum_gradients, model.trainable_variables))\n",
    "    \n",
    "    time_finish = time.time()\n",
    "    end_time = (time_finish-time_start)\n",
    "    time_record = time_record + '{:.3f} s \\n'.format(end_time)\n",
    "\n",
    "    if (epoch % log_freq == 0):\n",
    "        print ('Epoch: {}, Train Loss: {}, Train Acc:{}, Test Loss: {}, Test Acc: {}, Time: {} s'.format(\n",
    "               epoch,\n",
    "               train_loss.result(),\n",
    "               train_accuracy.result()*100,\n",
    "               test_loss.result(),\n",
    "               test_accuracy.result()*100,\n",
    "               end_time))\n",
    "\n",
    "        if (test_loss.result() < min_loss):    \n",
    "            if not os.path.exists(models_directory):\n",
    "                os.makedirs(models_directory)\n",
    "            # serialize weights to HDF5\n",
    "            model.save_weights(models_directory + \"best{}.h5\".format(identifier))\n",
    "            min_loss = test_loss.result()\n",
    "            min_loss_acc = test_accuracy.result()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "            #tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "            train_loss.reset_states()           \n",
    "            train_accuracy.reset_states()           \n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            test_loss.reset_states()           \n",
    "            test_accuracy.reset_states()   \n",
    "            # save confusion matrix\n",
    "            con_mat = tf.math.confusion_matrix(\n",
    "                labels=np.argmax(all_labels, axis=1), \n",
    "                predictions=np.argmax(all_predictions, axis=1),\n",
    "                num_classes=n_classes).numpy()\n",
    "            con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "            con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                                 index = classes, \n",
    "                                 columns = classes)\n",
    "            figure = plt.figure(figsize=(8, 8))\n",
    "            sns.heatmap(con_mat_df, annot=False,cmap=plt.cm.Blues)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(figure)\n",
    "            buf.seek(0)\n",
    "            image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "\n",
    "    if patience >= max_patience:\n",
    "        break\n",
    "\n",
    "with open(os.path.join('results/', identifier), \"w\") as file1:\n",
    "    file1.write(time_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
