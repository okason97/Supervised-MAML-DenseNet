{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from densenet import densenet_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From <ipython-input-2-0dcb167e88d7>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# data\n",
    "rotation_range = 20\n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2\n",
    "horizontal_flip = True\n",
    "vertical_flip = True\n",
    "shear_range = 0\n",
    "zoom_range = 0.5\n",
    "size = (32,32)\n",
    "\n",
    "# model\n",
    "nb_filter = 64\n",
    "growth_rate = 16\n",
    "nb_layers = [6, 12, 24, 16]\n",
    "reduction = 0.5\n",
    "\n",
    "# training\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "max_patience = 20\n",
    "batch_size = 128\n",
    "\n",
    "# log\n",
    "log_freq = 1\n",
    "models_directory = 'results/models/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"{}-growth-{}-densenet\".format(\n",
    "    '-'.join([str(i) for i in nb_layers]),\n",
    "    growth_rate) + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "ds_train = tfds.load('cifar100', split='train', shuffle_files=True, batch_size=-1)\n",
    "train_np_ds = tfds.as_numpy(ds_train)\n",
    "ds_test = tfds.load('cifar100', split='test', shuffle_files=False, batch_size=-1)\n",
    "test_np_ds = tfds.as_numpy(ds_test)\n",
    "\n",
    "x_train, y_train = train_np_ds[\"image\"], train_np_ds[\"label\"]\n",
    "x_test, y_test = test_np_ds[\"image\"], test_np_ds[\"label\"]\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]\n",
    "\n",
    "info = tfds.builder('cifar100').info\n",
    "n_classes = info.features['label'].num_classes\n",
    "img_shape = info.features['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=rotation_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip = vertical_flip,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "test_datagen.fit(x_train)\n",
    "\n",
    "# create data generators\n",
    "train_gen =  datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_gen = test_datagen.flow(x_test, y_test , batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [ 2.0511208  1.9624166  2.0611436]\n",
      "  [ 2.0395172  1.9538102  2.0530503]\n",
      "  [ 2.035955   1.9590038  2.048936 ]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [ 2.09295    2.0087667  2.10473  ]\n",
      "  [ 2.0728033  2.0010817  2.0975032]\n",
      "  [ 2.072745   2.001058   2.097481 ]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [ 2.0904963  2.007514   2.1035519]\n",
      "  [ 2.0733187  2.0022652  2.0980484]\n",
      "  [ 2.0784588  2.0130842  2.1031353]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]\n",
      "\n",
      " [[-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  ...\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]\n",
      "  [-1.3062079 -1.3746256 -1.2926631]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_gen:\n",
    "    print(images[0])\n",
    "    plt.imshow(images[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet_model(classes=n_classes, nb_filter=nb_filter, shape=img_shape, growth_rate=growth_rate, nb_layers=nb_layers, reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.cast(images, tf.float32), training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(tf.cast(images, tf.float32), training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary writers\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/train/' + identifier)\n",
    "test_summary_writer = tf.summary.create_file_writer('results/summaries/test/' + identifier)\n",
    "\n",
    "min_loss = 100\n",
    "min_loss_acc = 0\n",
    "patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "Epoch: 0, Train Loss: 4.090982437133789, Train Acc:7.541999816894531, Test Loss: 3.9585652351379395, Test Acc: 8.710000038146973, Time: 49.994138956069946 s\n",
      "Epoch: 1, Train Loss: 3.668987989425659, Train Acc:13.332000732421875, Test Loss: 3.7436087131500244, Test Acc: 13.470000267028809, Time: 26.158179759979248 s\n",
      "Epoch: 2, Train Loss: 3.4690463542938232, Train Acc:16.536001205444336, Test Loss: 3.46932053565979, Test Acc: 17.010000228881836, Time: 26.171755075454712 s\n",
      "Epoch: 3, Train Loss: 3.3196537494659424, Train Acc:19.062000274658203, Test Loss: 3.2828941345214844, Test Acc: 19.59000015258789, Time: 25.72245764732361 s\n",
      "Epoch: 4, Train Loss: 3.195955514907837, Train Acc:21.332000732421875, Test Loss: 3.5466506481170654, Test Acc: 17.260000228881836, Time: 26.109010219573975 s\n",
      "Epoch: 5, Train Loss: 3.092548131942749, Train Acc:22.86600112915039, Test Loss: 3.372166395187378, Test Acc: 19.5, Time: 25.522444486618042 s\n",
      "Epoch: 6, Train Loss: 3.0091495513916016, Train Acc:24.809999465942383, Test Loss: 3.1896770000457764, Test Acc: 22.65999984741211, Time: 24.639684200286865 s\n",
      "Epoch: 7, Train Loss: 2.9394097328186035, Train Acc:26.14000129699707, Test Loss: 3.2414894104003906, Test Acc: 22.05000114440918, Time: 26.038376331329346 s\n",
      "Epoch: 8, Train Loss: 2.868173122406006, Train Acc:27.669998168945312, Test Loss: 3.3674018383026123, Test Acc: 21.119998931884766, Time: 24.69619917869568 s\n",
      "Epoch: 9, Train Loss: 2.7949793338775635, Train Acc:28.87200164794922, Test Loss: 3.163722276687622, Test Acc: 24.51999855041504, Time: 24.812822103500366 s\n",
      "Epoch: 10, Train Loss: 2.738049268722534, Train Acc:29.857999801635742, Test Loss: 3.2791285514831543, Test Acc: 23.3799991607666, Time: 24.945006132125854 s\n",
      "Epoch: 11, Train Loss: 2.6846954822540283, Train Acc:30.924001693725586, Test Loss: 3.22859787940979, Test Acc: 23.84000015258789, Time: 24.808255910873413 s\n",
      "Epoch: 12, Train Loss: 2.645124673843384, Train Acc:31.860000610351562, Test Loss: 2.8994617462158203, Test Acc: 28.43000030517578, Time: 24.79909634590149 s\n",
      "Epoch: 13, Train Loss: 2.583402633666992, Train Acc:33.27799987792969, Test Loss: 3.1397287845611572, Test Acc: 26.499998092651367, Time: 24.600995540618896 s\n",
      "Epoch: 14, Train Loss: 2.543050765991211, Train Acc:33.875999450683594, Test Loss: 3.268756628036499, Test Acc: 24.959999084472656, Time: 24.684678316116333 s\n",
      "Epoch: 15, Train Loss: 2.4980320930480957, Train Acc:34.6619987487793, Test Loss: 2.910248279571533, Test Acc: 29.48000144958496, Time: 25.04933524131775 s\n",
      "Epoch: 16, Train Loss: 2.4480764865875244, Train Acc:35.85799789428711, Test Loss: 3.113675355911255, Test Acc: 26.920000076293945, Time: 24.521707773208618 s\n",
      "Epoch: 17, Train Loss: 2.4132542610168457, Train Acc:36.52000045776367, Test Loss: 3.249692440032959, Test Acc: 25.600000381469727, Time: 24.56601071357727 s\n",
      "Epoch: 18, Train Loss: 2.369675397872925, Train Acc:37.301998138427734, Test Loss: 3.1802659034729004, Test Acc: 27.170000076293945, Time: 24.41279888153076 s\n",
      "Epoch: 19, Train Loss: 2.3394622802734375, Train Acc:38.15999984741211, Test Loss: 2.9011082649230957, Test Acc: 30.759998321533203, Time: 24.546359062194824 s\n",
      "Epoch: 20, Train Loss: 2.303959846496582, Train Acc:38.8859977722168, Test Loss: 2.777693748474121, Test Acc: 32.51000213623047, Time: 24.918533086776733 s\n",
      "Epoch: 21, Train Loss: 2.263105869293213, Train Acc:39.54199981689453, Test Loss: 2.8755266666412354, Test Acc: 31.470001220703125, Time: 24.762521266937256 s\n",
      "Epoch: 22, Train Loss: 2.226492166519165, Train Acc:40.503997802734375, Test Loss: 3.2107222080230713, Test Acc: 28.029998779296875, Time: 24.90049457550049 s\n",
      "Epoch: 23, Train Loss: 2.2002694606781006, Train Acc:40.9379997253418, Test Loss: 2.8946304321289062, Test Acc: 30.779998779296875, Time: 26.55907702445984 s\n",
      "Epoch: 24, Train Loss: 2.1647815704345703, Train Acc:41.94200134277344, Test Loss: 2.9985241889953613, Test Acc: 31.630001068115234, Time: 25.434121131896973 s\n",
      "Epoch: 25, Train Loss: 2.1286072731018066, Train Acc:42.51799774169922, Test Loss: 2.9096410274505615, Test Acc: 32.12000274658203, Time: 25.596484422683716 s\n",
      "Epoch: 26, Train Loss: 2.0864057540893555, Train Acc:43.42399978637695, Test Loss: 2.631176233291626, Test Acc: 36.0099983215332, Time: 25.32231855392456 s\n",
      "Epoch: 27, Train Loss: 2.0623762607574463, Train Acc:44.082000732421875, Test Loss: 3.1527369022369385, Test Acc: 29.719999313354492, Time: 25.597021341323853 s\n",
      "Epoch: 28, Train Loss: 2.033919095993042, Train Acc:44.89799880981445, Test Loss: 2.7422754764556885, Test Acc: 34.20000076293945, Time: 25.81743049621582 s\n",
      "Epoch: 29, Train Loss: 2.0021796226501465, Train Acc:45.332000732421875, Test Loss: 2.823822498321533, Test Acc: 32.83000183105469, Time: 25.272676467895508 s\n",
      "Epoch: 30, Train Loss: 1.9813185930252075, Train Acc:45.917999267578125, Test Loss: 2.8087849617004395, Test Acc: 34.220001220703125, Time: 25.7187922000885 s\n",
      "Epoch: 31, Train Loss: 1.9369139671325684, Train Acc:46.72200012207031, Test Loss: 3.0492303371429443, Test Acc: 31.560001373291016, Time: 25.144346237182617 s\n",
      "Epoch: 32, Train Loss: 1.914462924003601, Train Acc:47.26000213623047, Test Loss: 2.684530019760132, Test Acc: 35.37000274658203, Time: 25.2801251411438 s\n",
      "Epoch: 33, Train Loss: 1.8948869705200195, Train Acc:47.95000076293945, Test Loss: 2.7711222171783447, Test Acc: 35.81999969482422, Time: 25.905940771102905 s\n",
      "Epoch: 34, Train Loss: 1.8697717189788818, Train Acc:48.34400177001953, Test Loss: 2.5717482566833496, Test Acc: 38.0, Time: 25.490458250045776 s\n",
      "Epoch: 35, Train Loss: 1.8370144367218018, Train Acc:48.8120002746582, Test Loss: 3.0189738273620605, Test Acc: 32.5, Time: 25.8336181640625 s\n",
      "Epoch: 36, Train Loss: 1.8037359714508057, Train Acc:49.913997650146484, Test Loss: 2.797865152359009, Test Acc: 36.0, Time: 25.21426248550415 s\n",
      "Epoch: 37, Train Loss: 1.79512357711792, Train Acc:49.95399856567383, Test Loss: 2.9594979286193848, Test Acc: 33.709999084472656, Time: 25.338733196258545 s\n",
      "Epoch: 38, Train Loss: 1.764114260673523, Train Acc:50.65199661254883, Test Loss: 2.6876072883605957, Test Acc: 36.68000030517578, Time: 25.66861057281494 s\n",
      "Epoch: 39, Train Loss: 1.748549222946167, Train Acc:51.22200393676758, Test Loss: 2.8653461933135986, Test Acc: 35.56999969482422, Time: 26.066591501235962 s\n",
      "Epoch: 40, Train Loss: 1.7191390991210938, Train Acc:52.003997802734375, Test Loss: 2.9306483268737793, Test Acc: 34.92000198364258, Time: 25.997299194335938 s\n",
      "Epoch: 41, Train Loss: 1.689078450202942, Train Acc:52.85199737548828, Test Loss: 2.7195560932159424, Test Acc: 37.16999816894531, Time: 25.772632598876953 s\n",
      "Epoch: 42, Train Loss: 1.6776340007781982, Train Acc:52.8599967956543, Test Loss: 2.781864643096924, Test Acc: 35.90999984741211, Time: 25.677040338516235 s\n",
      "Epoch: 43, Train Loss: 1.6442103385925293, Train Acc:53.81399917602539, Test Loss: 2.8030433654785156, Test Acc: 36.93000030517578, Time: 25.19175696372986 s\n",
      "Epoch: 44, Train Loss: 1.619311809539795, Train Acc:53.97999954223633, Test Loss: 2.8778748512268066, Test Acc: 36.0, Time: 25.097896099090576 s\n",
      "Epoch: 45, Train Loss: 1.598523497581482, Train Acc:54.70000076293945, Test Loss: 2.653938055038452, Test Acc: 38.29999923706055, Time: 25.140361785888672 s\n",
      "Epoch: 46, Train Loss: 1.5788902044296265, Train Acc:55.08599853515625, Test Loss: 3.0528008937835693, Test Acc: 34.68000030517578, Time: 26.10571599006653 s\n",
      "Epoch: 47, Train Loss: 1.56329345703125, Train Acc:55.459999084472656, Test Loss: 3.1100783348083496, Test Acc: 34.06999969482422, Time: 25.880154609680176 s\n",
      "Epoch: 48, Train Loss: 1.5430241823196411, Train Acc:56.0260009765625, Test Loss: 2.7869157791137695, Test Acc: 36.53999710083008, Time: 26.85250997543335 s\n",
      "Epoch: 49, Train Loss: 1.529575228691101, Train Acc:56.50200271606445, Test Loss: 3.056549072265625, Test Acc: 34.689998626708984, Time: 25.29236364364624 s\n",
      "Epoch: 50, Train Loss: 1.5188326835632324, Train Acc:56.5359992980957, Test Loss: 2.8705825805664062, Test Acc: 36.71999740600586, Time: 25.136061668395996 s\n",
      "Epoch: 51, Train Loss: 1.483608365058899, Train Acc:57.599998474121094, Test Loss: 2.8420865535736084, Test Acc: 37.43000030517578, Time: 25.876691102981567 s\n",
      "Epoch: 52, Train Loss: 1.4611886739730835, Train Acc:58.012001037597656, Test Loss: 2.8803083896636963, Test Acc: 37.13999938964844, Time: 25.430023670196533 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Train Loss: 1.4515031576156616, Train Acc:58.384002685546875, Test Loss: 2.81685733795166, Test Acc: 37.94000244140625, Time: 25.541655778884888 s\n",
      "Epoch: 54, Train Loss: 1.4280697107315063, Train Acc:59.0160026550293, Test Loss: 3.114351511001587, Test Acc: 35.20000076293945, Time: 26.29706072807312 s\n"
     ]
    }
   ],
   "source": [
    "print(\"starting training\")\n",
    "time_record = ''\n",
    "for epoch in range(epochs):\n",
    "    time_start = time.time()\n",
    "    batches = 0\n",
    "    for images, labels in train_gen:\n",
    "        train_step(images, labels)\n",
    "        batches += 1\n",
    "        if batches >= train_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    batches = 0\n",
    "    all_predictions = np.array([]).reshape(0, n_classes)\n",
    "    all_labels = np.array([]).reshape(0, n_classes)\n",
    "    for test_images, test_labels in test_gen:\n",
    "        all_predictions = np.vstack((all_predictions, test_step(test_images, test_labels)))\n",
    "        all_labels = np.vstack((all_labels, tf.one_hot(test_labels, n_classes)))\n",
    "        batches += 1\n",
    "        if batches >= test_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    time_finish = time.time()\n",
    "    end_time = (time_finish-time_start)\n",
    "    time_record = time_record + '{:.3f} s \\n'.format(end_time)\n",
    "\n",
    "    if (epoch % log_freq == 0):\n",
    "        print ('Epoch: {}, Train Loss: {}, Train Acc:{}, Test Loss: {}, Test Acc: {}, Time: {} s'.format(\n",
    "               epoch,\n",
    "               train_loss.result(),\n",
    "               train_accuracy.result()*100,\n",
    "               test_loss.result(),\n",
    "               test_accuracy.result()*100,\n",
    "               end_time))\n",
    "\n",
    "        if (test_loss.result() < min_loss):    \n",
    "            if not os.path.exists(models_directory):\n",
    "                os.makedirs(models_directory)\n",
    "            # serialize weights to HDF5\n",
    "            model.save_weights(models_directory + \"best{}.h5\".format(identifier))\n",
    "            min_loss = test_loss.result()\n",
    "            min_loss_acc = test_accuracy.result()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "            #tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "            train_loss.reset_states()           \n",
    "            train_accuracy.reset_states()           \n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            test_loss.reset_states()           \n",
    "            test_accuracy.reset_states()   \n",
    "            # save confusion matrix\n",
    "            con_mat = tf.math.confusion_matrix(\n",
    "                labels=np.argmax(all_labels, axis=1), \n",
    "                predictions=np.argmax(all_predictions, axis=1),\n",
    "                num_classes=n_classes).numpy()\n",
    "            con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "            con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                                 index = classes, \n",
    "                                 columns = classes)\n",
    "            figure = plt.figure(figsize=(8, 8))\n",
    "            sns.heatmap(con_mat_df, annot=False,cmap=plt.cm.Blues)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(figure)\n",
    "            buf.seek(0)\n",
    "            image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            tf.summary.image('Confusion Matrix', image, step=epoch)\n",
    "\n",
    "    if patience >= max_patience:\n",
    "        break\n",
    "\n",
    "with open(os.path.join('results/', identifier), \"w\") as file1:\n",
    "    file1.write(time_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
